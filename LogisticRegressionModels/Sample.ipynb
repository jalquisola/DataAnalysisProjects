{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DESCR': 'Iris Plants Database\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n',\n",
       " 'data': array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "        [ 4.9,  3. ,  1.4,  0.2],\n",
       "        [ 4.7,  3.2,  1.3,  0.2],\n",
       "        [ 4.6,  3.1,  1.5,  0.2],\n",
       "        [ 5. ,  3.6,  1.4,  0.2],\n",
       "        [ 5.4,  3.9,  1.7,  0.4],\n",
       "        [ 4.6,  3.4,  1.4,  0.3],\n",
       "        [ 5. ,  3.4,  1.5,  0.2],\n",
       "        [ 4.4,  2.9,  1.4,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5.4,  3.7,  1.5,  0.2],\n",
       "        [ 4.8,  3.4,  1.6,  0.2],\n",
       "        [ 4.8,  3. ,  1.4,  0.1],\n",
       "        [ 4.3,  3. ,  1.1,  0.1],\n",
       "        [ 5.8,  4. ,  1.2,  0.2],\n",
       "        [ 5.7,  4.4,  1.5,  0.4],\n",
       "        [ 5.4,  3.9,  1.3,  0.4],\n",
       "        [ 5.1,  3.5,  1.4,  0.3],\n",
       "        [ 5.7,  3.8,  1.7,  0.3],\n",
       "        [ 5.1,  3.8,  1.5,  0.3],\n",
       "        [ 5.4,  3.4,  1.7,  0.2],\n",
       "        [ 5.1,  3.7,  1.5,  0.4],\n",
       "        [ 4.6,  3.6,  1. ,  0.2],\n",
       "        [ 5.1,  3.3,  1.7,  0.5],\n",
       "        [ 4.8,  3.4,  1.9,  0.2],\n",
       "        [ 5. ,  3. ,  1.6,  0.2],\n",
       "        [ 5. ,  3.4,  1.6,  0.4],\n",
       "        [ 5.2,  3.5,  1.5,  0.2],\n",
       "        [ 5.2,  3.4,  1.4,  0.2],\n",
       "        [ 4.7,  3.2,  1.6,  0.2],\n",
       "        [ 4.8,  3.1,  1.6,  0.2],\n",
       "        [ 5.4,  3.4,  1.5,  0.4],\n",
       "        [ 5.2,  4.1,  1.5,  0.1],\n",
       "        [ 5.5,  4.2,  1.4,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5. ,  3.2,  1.2,  0.2],\n",
       "        [ 5.5,  3.5,  1.3,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 4.4,  3. ,  1.3,  0.2],\n",
       "        [ 5.1,  3.4,  1.5,  0.2],\n",
       "        [ 5. ,  3.5,  1.3,  0.3],\n",
       "        [ 4.5,  2.3,  1.3,  0.3],\n",
       "        [ 4.4,  3.2,  1.3,  0.2],\n",
       "        [ 5. ,  3.5,  1.6,  0.6],\n",
       "        [ 5.1,  3.8,  1.9,  0.4],\n",
       "        [ 4.8,  3. ,  1.4,  0.3],\n",
       "        [ 5.1,  3.8,  1.6,  0.2],\n",
       "        [ 4.6,  3.2,  1.4,  0.2],\n",
       "        [ 5.3,  3.7,  1.5,  0.2],\n",
       "        [ 5. ,  3.3,  1.4,  0.2],\n",
       "        [ 7. ,  3.2,  4.7,  1.4],\n",
       "        [ 6.4,  3.2,  4.5,  1.5],\n",
       "        [ 6.9,  3.1,  4.9,  1.5],\n",
       "        [ 5.5,  2.3,  4. ,  1.3],\n",
       "        [ 6.5,  2.8,  4.6,  1.5],\n",
       "        [ 5.7,  2.8,  4.5,  1.3],\n",
       "        [ 6.3,  3.3,  4.7,  1.6],\n",
       "        [ 4.9,  2.4,  3.3,  1. ],\n",
       "        [ 6.6,  2.9,  4.6,  1.3],\n",
       "        [ 5.2,  2.7,  3.9,  1.4],\n",
       "        [ 5. ,  2. ,  3.5,  1. ],\n",
       "        [ 5.9,  3. ,  4.2,  1.5],\n",
       "        [ 6. ,  2.2,  4. ,  1. ],\n",
       "        [ 6.1,  2.9,  4.7,  1.4],\n",
       "        [ 5.6,  2.9,  3.6,  1.3],\n",
       "        [ 6.7,  3.1,  4.4,  1.4],\n",
       "        [ 5.6,  3. ,  4.5,  1.5],\n",
       "        [ 5.8,  2.7,  4.1,  1. ],\n",
       "        [ 6.2,  2.2,  4.5,  1.5],\n",
       "        [ 5.6,  2.5,  3.9,  1.1],\n",
       "        [ 5.9,  3.2,  4.8,  1.8],\n",
       "        [ 6.1,  2.8,  4. ,  1.3],\n",
       "        [ 6.3,  2.5,  4.9,  1.5],\n",
       "        [ 6.1,  2.8,  4.7,  1.2],\n",
       "        [ 6.4,  2.9,  4.3,  1.3],\n",
       "        [ 6.6,  3. ,  4.4,  1.4],\n",
       "        [ 6.8,  2.8,  4.8,  1.4],\n",
       "        [ 6.7,  3. ,  5. ,  1.7],\n",
       "        [ 6. ,  2.9,  4.5,  1.5],\n",
       "        [ 5.7,  2.6,  3.5,  1. ],\n",
       "        [ 5.5,  2.4,  3.8,  1.1],\n",
       "        [ 5.5,  2.4,  3.7,  1. ],\n",
       "        [ 5.8,  2.7,  3.9,  1.2],\n",
       "        [ 6. ,  2.7,  5.1,  1.6],\n",
       "        [ 5.4,  3. ,  4.5,  1.5],\n",
       "        [ 6. ,  3.4,  4.5,  1.6],\n",
       "        [ 6.7,  3.1,  4.7,  1.5],\n",
       "        [ 6.3,  2.3,  4.4,  1.3],\n",
       "        [ 5.6,  3. ,  4.1,  1.3],\n",
       "        [ 5.5,  2.5,  4. ,  1.3],\n",
       "        [ 5.5,  2.6,  4.4,  1.2],\n",
       "        [ 6.1,  3. ,  4.6,  1.4],\n",
       "        [ 5.8,  2.6,  4. ,  1.2],\n",
       "        [ 5. ,  2.3,  3.3,  1. ],\n",
       "        [ 5.6,  2.7,  4.2,  1.3],\n",
       "        [ 5.7,  3. ,  4.2,  1.2],\n",
       "        [ 5.7,  2.9,  4.2,  1.3],\n",
       "        [ 6.2,  2.9,  4.3,  1.3],\n",
       "        [ 5.1,  2.5,  3. ,  1.1],\n",
       "        [ 5.7,  2.8,  4.1,  1.3],\n",
       "        [ 6.3,  3.3,  6. ,  2.5],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 7.1,  3. ,  5.9,  2.1],\n",
       "        [ 6.3,  2.9,  5.6,  1.8],\n",
       "        [ 6.5,  3. ,  5.8,  2.2],\n",
       "        [ 7.6,  3. ,  6.6,  2.1],\n",
       "        [ 4.9,  2.5,  4.5,  1.7],\n",
       "        [ 7.3,  2.9,  6.3,  1.8],\n",
       "        [ 6.7,  2.5,  5.8,  1.8],\n",
       "        [ 7.2,  3.6,  6.1,  2.5],\n",
       "        [ 6.5,  3.2,  5.1,  2. ],\n",
       "        [ 6.4,  2.7,  5.3,  1.9],\n",
       "        [ 6.8,  3. ,  5.5,  2.1],\n",
       "        [ 5.7,  2.5,  5. ,  2. ],\n",
       "        [ 5.8,  2.8,  5.1,  2.4],\n",
       "        [ 6.4,  3.2,  5.3,  2.3],\n",
       "        [ 6.5,  3. ,  5.5,  1.8],\n",
       "        [ 7.7,  3.8,  6.7,  2.2],\n",
       "        [ 7.7,  2.6,  6.9,  2.3],\n",
       "        [ 6. ,  2.2,  5. ,  1.5],\n",
       "        [ 6.9,  3.2,  5.7,  2.3],\n",
       "        [ 5.6,  2.8,  4.9,  2. ],\n",
       "        [ 7.7,  2.8,  6.7,  2. ],\n",
       "        [ 6.3,  2.7,  4.9,  1.8],\n",
       "        [ 6.7,  3.3,  5.7,  2.1],\n",
       "        [ 7.2,  3.2,  6. ,  1.8],\n",
       "        [ 6.2,  2.8,  4.8,  1.8],\n",
       "        [ 6.1,  3. ,  4.9,  1.8],\n",
       "        [ 6.4,  2.8,  5.6,  2.1],\n",
       "        [ 7.2,  3. ,  5.8,  1.6],\n",
       "        [ 7.4,  2.8,  6.1,  1.9],\n",
       "        [ 7.9,  3.8,  6.4,  2. ],\n",
       "        [ 6.4,  2.8,  5.6,  2.2],\n",
       "        [ 6.3,  2.8,  5.1,  1.5],\n",
       "        [ 6.1,  2.6,  5.6,  1.4],\n",
       "        [ 7.7,  3. ,  6.1,  2.3],\n",
       "        [ 6.3,  3.4,  5.6,  2.4],\n",
       "        [ 6.4,  3.1,  5.5,  1.8],\n",
       "        [ 6. ,  3. ,  4.8,  1.8],\n",
       "        [ 6.9,  3.1,  5.4,  2.1],\n",
       "        [ 6.7,  3.1,  5.6,  2.4],\n",
       "        [ 6.9,  3.1,  5.1,  2.3],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 6.8,  3.2,  5.9,  2.3],\n",
       "        [ 6.7,  3.3,  5.7,  2.5],\n",
       "        [ 6.7,  3. ,  5.2,  2.3],\n",
       "        [ 6.3,  2.5,  5. ,  1.9],\n",
       "        [ 6.5,  3. ,  5.2,  2. ],\n",
       "        [ 6.2,  3.4,  5.4,  2.3],\n",
       "        [ 5.9,  3. ,  5.1,  1.8]]),\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], \n",
       "       dtype='<U10')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = iris.data[:, [2,3]]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_std = sc.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "ppn = Perceptron(n_iter=40, eta0=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=0.1, fit_intercept=True,\n",
       "      n_iter=40, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
       "      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = ppn.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Misclassified samples: %d\" % (y_test != y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: %.2f\" % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=1000.0, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=0,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_y_pred = lr.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: %.2f\" % accuracy_score(y_test, lr_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joseph/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  2.05743774e-11,   6.31620264e-02,   9.36837974e-01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict_proba(X_test_std[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights, params = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -4.49510992e-04  -4.35759439e-04]\n",
      " [  6.55979672e-05   3.27209902e-05]\n",
      " [  3.83913024e-04   4.03038448e-04]]\n",
      "[[-0.00447462 -0.00433712]\n",
      " [ 0.00065369  0.00032495]\n",
      " [ 0.00382093  0.00401217]]\n",
      "[[-0.04279921 -0.04142528]\n",
      " [ 0.00631937  0.00303439]\n",
      " [ 0.03647965  0.03839056]]\n",
      "[[-0.30300251 -0.28948713]\n",
      " [ 0.04881993  0.01620922]\n",
      " [ 0.25366974  0.27257538]]\n",
      "[[-1.00342689 -0.90364533]\n",
      " [ 0.23882448 -0.06648319]\n",
      " [ 0.77522834  0.93509211]]\n",
      "[[-2.09336507 -1.76672619]\n",
      " [ 1.06011115 -0.84154482]\n",
      " [ 1.72637718  2.36915927]]\n",
      "[[-3.52802958 -3.04636269]\n",
      " [ 2.19190886 -1.98265142]\n",
      " [ 3.87719037  4.50869136]]\n",
      "[[-5.22828976 -4.78409778]\n",
      " [ 2.50582212 -2.30336729]\n",
      " [ 7.40534995  5.98765803]]\n",
      "[[-7.34015187 -6.64685581]\n",
      " [ 2.54373335 -2.3421979 ]\n",
      " [ 9.46617627  6.44380858]]\n",
      "[[-9.38725178 -8.62196104]\n",
      " [ 2.54760621 -2.34616582]\n",
      " [ 9.8260878   6.51345035]]\n"
     ]
    }
   ],
   "source": [
    "for c in np.arange(-5, 5):\n",
    "    lr = LogisticRegression(C=10**c, random_state=0)\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    print(lr.coef_)\n",
    "    weights.append(lr.coef_[1])\n",
    "    params.append(10**c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = np.array(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAETCAYAAAAs4pGmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117f5cb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(params, weights[:, 0], label='petal length')\n",
    "plt.plot(params, weights[:,1], linestyle='--',label='width')\n",
    "plt.ylabel('weight coefficient')\n",
    "plt.xlabel('C')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=1, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=2,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest_y_pred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Score: 0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"RandomForestClassifier Score: %.2f\" % accuracy_score(y_test, forest_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
